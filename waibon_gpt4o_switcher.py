# waibon_gpt4o_switcher.py
import os
import openai
from dotenv import load_dotenv

# ‡πÇ‡∏´‡∏•‡∏î API Key ‡∏à‡∏≤‡∏Å .env (‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏Å‡πá‡πÑ‡∏î‡πâ)
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
current_model = "llama-3"

def switch_model(model_name):
    global current_model
    if model_name in ["llama-3", "gpt-4o"]:
        current_model = model_name
        return f"‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô: {current_model}"
    else:
        return f"‚ùå ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• '{model_name}'"

def get_model_status():
    return f"üìç ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠: {current_model}"

def ask_llama(prompt):
    # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö LLaMA (‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° Groq ‡∏´‡∏£‡∏∑‡∏≠ Ollama ‡πÅ‡∏ó‡∏ô)
    return f"[LLaMA] ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö: {prompt}", "llama-3"

def ask_gpt4o(prompt):
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are Waibon, beat analysis expert."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        return response.choices[0].message.content, "gpt-4o"
    except Exception as e:
        return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}", "error"

def waibon_ask(text):
    if text.startswith("@llama"):
        return ask_llama(text.replace("@llama", "", 1).strip())
    elif text.startswith("@gpt4o"):
        return ask_gpt4o(text.replace("@gpt4o", "", 1).strip())
    elif text.startswith("@status"):
        return get_model_status(), current_model
    elif text.startswith("@analyze"):
        topic = text.replace("@analyze", "").strip()
        return f"üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: {topic} ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• {current_model}", current_model
    else:
        if current_model == "llama-3":
            return ask_llama(text)
        elif current_model == "gpt-4o":
            return ask_gpt4o(text)
        else:
            return "‚ùå ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà", "unknown"
